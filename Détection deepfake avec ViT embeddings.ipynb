{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 1. IMPORTS\n",
    "# =====================\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa7ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 2. CHARGER ViT pré-entraîné\n",
    "# =====================\n",
    "model_name = \"google/vit-base-patch16-224-in21k\"\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
    "vit_model = ViTModel.from_pretrained(model_name).to(device)\n",
    "vit_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 3. EXTRACTION DE FRAMES D’UNE VIDÉO\n",
    "# =====================\n",
    "def extract_frames(video_path, every_n=10):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if idx % every_n == 0:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame_rgb)\n",
    "        idx += 1\n",
    "    cap.release()\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 4. OBTENIR LES EMBEDDINGS VIT POUR UNE LISTE D’IMAGES\n",
    "# =====================\n",
    "def get_vit_embeddings(frames):\n",
    "    inputs = feature_extractor(images=frames, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = vit_model(**inputs)\n",
    "    # On récupère le token [CLS] → taille 768\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19239a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 5. MOYENNE DES EMBEDDINGS PAR VIDÉO\n",
    "# =====================\n",
    "def process_video(video_path):\n",
    "    frames = extract_frames(video_path, every_n=10)  # Une frame sur 10\n",
    "    if not frames:\n",
    "        return None\n",
    "    embeddings = get_vit_embeddings(frames)\n",
    "    video_embedding = np.mean(embeddings, axis=0)  # Moyenne des frames\n",
    "    return video_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d22d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 6. CRÉATION DU DATASET\n",
    "# =====================\n",
    "def create_dataset(real_dir, fake_dir):\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Réelles\n",
    "    for video_path in tqdm(glob.glob(os.path.join(real_dir, \"*.mp4\"))):\n",
    "        emb = process_video(video_path)\n",
    "        if emb is not None:\n",
    "            X.append(emb)\n",
    "            y.append(0)\n",
    "    \n",
    "    # Fakes\n",
    "    for video_path in tqdm(glob.glob(os.path.join(fake_dir, \"*.mp4\"))):\n",
    "        emb = process_video(video_path)\n",
    "        if emb is not None:\n",
    "            X.append(emb)\n",
    "            y.append(1)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "real_videos_path = r\"C:\\Users\\EliteLaptop\\Desktop\\kawtar\\GAN_inversion\\real_videos\"\n",
    "fake_videos_path = r\"C:\\Users\\EliteLaptop\\Desktop\\kawtar\\GAN_inversion\\fake_videos\"\n",
    "\n",
    "X, y = create_dataset(real_videos_path, fake_videos_path)\n",
    "print(\"Shape X:\", X.shape, \"Shape y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eedeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 7. ENTRAÎNEMENT DU CLASSIFIEUR\n",
    "# =====================\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = SVC(kernel=\"linear\", probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Real\", \"Fake\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 8. PRÉDICTION SUR UNE NOUVELLE VIDÉO\n",
    "# =====================\n",
    "def predict_video(video_path):\n",
    "    emb = process_video(video_path)\n",
    "    if emb is None:\n",
    "        print(\"Pas de frames extraites.\")\n",
    "        return None\n",
    "    pred = clf.predict([emb])[0]\n",
    "    return \"Fake\" if pred == 1 else \"Real\"\n",
    "\n",
    "test_video = r\"C:\\path\\to\\test_video.mp4\"\n",
    "print(\"Résultat :\", predict_video(test_video))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
